{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"api_to_use/","title":"Api to use","text":""},{"location":"api_to_use/#ai-suggestion","title":"AI Suggestion","text":""},{"location":"api_to_use/#clade-ai","title":"Clade AI","text":"<p>1. Global Biodiversity Information Facility (GBIF): The GBIF API provides access to billions of records about species occurrences, distributions, and traits from thousands of data publishers worldwide. This is an excellent source for obtaining basic species data.</p> <p>2. IUCN Red List of Threatened Species: The IUCN Red List is a comprehensive inventory of the global conservation status of plant and animal species. It includes data on population trends, threats, and conservation actions for endangered species.</p> <p>3. Integrated Taxonomic Information System (ITIS): ITIS is a database of standardized scientific and common names for species, with classifications, notes, and cross-references. It's useful for taxonomic information and validating species names.</p> <p>4. VertNet, FishNet2, MaNIS, HerpNET, ORNIS: These are biodiversity data portals that aggregate species occurrence data from natural history museums and other institutions, focusing on specific taxonomic groups like vertebrates, fish, mammals, herps, and birds.</p> <p>5. DataONE: DataONE is a repository of ecological and environmental datasets, including many related to species and biodiversity. You can search for and access a wide range of species-focused datasets.</p> <p>6. Database tools: - For storing and managing species data, consider using a relational database like PostgreSQL or MySQL, or a NoSQL database like MongoDB or Elasticsearch. - Visualization tools like Tableau, Power BI, or Plotly can help analyze and plot species population trends, conservation status, and other metrics over time. - Modeling and analysis tools like R, Python, and GIS software can be used for more advanced population viability analysis, species distribution modeling, and interaction matrix development.</p> <p>7. Citizen science platforms: Platforms like iNaturalist, eBird, and PlantNet allow the public to contribute observations of species, which can supplement official datasets.</p>"},{"location":"api_to_use/#chatgpt","title":"ChatGPT","text":"<ol> <li>Global Biodiversity Information Facility (GBIF): GBIF is excellent for large-scale biodiversity data, especially for species occurrence records, geographic distribution, and taxonomy. You can use the GBIF API to access data on species observations, specimen collections, and checklists.</li> <li>Encyclopedia of Life (EOL): EOL has extensive species descriptions, habitat information, conservation status, and multimedia resources. Their API offers access to species data and taxonomic hierarchy, which can help with species interaction and habitat mapping.</li> <li>iNaturalist: This citizen science platform is rich in observational data and time series data for species occurrences, allowing insights into population changes over time. You can use the iNaturalist API for real-time species sightings.</li> <li>Atlas of Living Australia (ALA): The ALA provides a vast amount of biodiversity data, including species interactions, habitat, and ecosystem data. It\u2019s particularly strong for Australian biodiversity but connects with other global datasets. The ALA API allows access to occurrence records, taxonomy, and species interactions.</li> <li>Biodiversity Heritage Library (BHL): BHL archives historical biodiversity literature and can be valuable for legacy species data and historical population data. They offer an API for accessing publications and species descriptions.</li> <li>National Center for Biotechnology Information (NCBI) Taxonomy and GenBank: For more genetic and taxonomy-focused data, NCBI has species records and genetic sequence data. The NCBI Taxonomy API could complement ecological data with phylogenetic information.</li> <li>Map of Life (MoL): MoL provides data on species distribution, ranges, and environmental interactions. This data can be useful for identifying regional data and understanding the habitat preferences of species.</li> </ol>"},{"location":"api_to_use/#apis","title":"APIs","text":""},{"location":"api_to_use/#gbif","title":"GBIF","text":"<p>Here are some of the key GBIF API endpoints that may be useful for accessing species data:</p> <pre><code>{\n  \"occurrences\": \"/v1/occurrence/search\",\n  \"species\": \"/v1/species/search\",\n  \"speciesById\": \"/v1/species/{speciesKey}\",\n  \"datasets\": \"/v1/dataset/search\",\n  \"datasetsByKey\": \"/v1/dataset/{datasetKey}\",\n  \"homepageFacts\": \"/v1/dashboard/facts\",\n  \"metrics\": \"/v1/metrics/occurrence\",\n  \"downloads\": \"/v1/occurrence/download/request\",\n  \"downloadStatus\": \"/v1/occurrence/download/{downloadKey}\"\n}\n</code></pre> <p>Here's a brief overview of how you can use these endpoints:</p> <ol> <li> <p>Occurrences: The <code>/v1/occurrence/search</code> endpoint allows you to search for and retrieve species occurrence records, including location, date, and other metadata.</p> </li> <li> <p>Species: The <code>/v1/species/search</code> endpoint lets you search for species by various criteria like scientific name, common name, or taxonomy. The <code>/v1/species/{speciesKey}</code> endpoint retrieves details for a specific species.</p> </li> <li> <p>Datasets: The <code>/v1/dataset/search</code> endpoint lists the available datasets on GBIF. The <code>/v1/dataset/{datasetKey}</code> endpoint provides more details on a specific dataset.</p> </li> <li> <p>Dashboard Facts: The <code>/v1/dashboard/facts</code> endpoint returns high-level statistics and facts about the GBIF network.</p> </li> <li> <p>Metrics: The <code>/v1/metrics/occurrence</code> endpoint provides aggregated metrics about the occurrence data in GBIF.</p> </li> <li> <p>Downloads: You can use the <code>/v1/occurrence/download/request</code> endpoint to request a dataset download, and then check the status of the download using the <code>/v1/occurrence/download/{downloadKey}</code> endpoint.</p> </li> </ol> <p>This covers some of the most commonly used GBIF API endpoints for accessing species data. Let me know if you need any clarification or have additional questions!</p>"},{"location":"clear/","title":"Clear","text":"<p>Writing clear Python code requires several key considerations that make your code readable, maintainable, and efficient:</p> <p>Note</p> <p>This is a note!</p> <p>Warning</p> <p>This is a warning!</p> <ol> <li>Follow PEP 8 Guidelines:</li> <li> <p>PEP 8 is the official style guide for Python. It covers everything from indentation to naming conventions, ensuring consistent code structure. For example:</p> <ul> <li>Use 4 spaces per indentation level.</li> <li>Limit lines to 79 characters.</li> </ul> </li> <li> <p>Use Meaningful Variable and Function Names:</p> </li> <li>Choose descriptive names that reflect the purpose of the variable or function.</li> <li> <p>Example: Use <code>calculate_total_cost()</code> instead of <code>calc()</code>.</p> </li> <li> <p>Write Modular Code:</p> </li> <li> <p>Break down large tasks into smaller, reusable functions. This makes your code more organized and easier to test.</p> </li> <li> <p>Document Your Code:</p> </li> <li> <p>Use comments and docstrings to explain why certain decisions were made or what a function is supposed to do. This helps other developers (and your future self) understand the code.</p> </li> <li> <p>Keep Functions and Classes Simple:</p> </li> <li> <p>Follow the single responsibility principle: each function or class should have one purpose. Complex functions are harder to understand and maintain.</p> </li> <li> <p>Avoid Hardcoding:</p> </li> <li> <p>Use constants, configuration files, or environment variables to make your code adaptable to different contexts or environments.</p> </li> <li> <p>Handle Errors Gracefully:</p> </li> <li> <p>Use exceptions to manage errors in a way that doesn\u2019t crash the program. Provide clear error messages when something goes wrong.</p> </li> <li> <p>Optimize for Readability Over Cleverness:</p> </li> <li> <p>Avoid writing overly complex or tricky code. Opt for readability, even if the code looks simpler or less \"sophisticated.\"</p> </li> <li> <p>Use List Comprehensions (But Not Excessively):</p> </li> <li> <p>Python\u2019s list comprehensions are concise and readable, but avoid nesting too deeply. Use them when they improve readability.</p> </li> <li> <p>Consistent Naming Conventions:</p> <ul> <li>Follow conventions like:</li> <li><code>snake_case</code> for variables and function names.</li> <li><code>CamelCase</code> for classes.</li> <li><code>_</code> prefix for private variables or functions.</li> </ul> </li> </ol> <p>By adhering to these principles, you'll write Python code that's not only clear to you but also easy for others to read and maintain.</p> <p>Yes, apart from SOLID principles, there are several other design principles and methodologies used to improve software architecture and maintainability. Here are a few prominent ones:</p>"},{"location":"clear/#1-dry-dont-repeat-yourself","title":"1. DRY - Don't Repeat Yourself","text":"<p>This principle suggests that you should avoid duplicating code. Instead of repeating code in multiple places, abstract the common functionality into a single location (function, class, or module).</p> <p>Example: <pre><code>def calculate_tax(price):\n    return price * 0.2\n\ndef print_receipt(price):\n    total_price = price + calculate_tax(price)\n    print(f\"Price: {price}, Total (with tax): {total_price}\")\n</code></pre></p> <p>Here, the <code>calculate_tax()</code> function is reused wherever tax calculation is needed, avoiding code repetition.</p>"},{"location":"clear/#2-kiss-keep-it-simple-stupid","title":"2. KISS - Keep It Simple, Stupid","text":"<p>This principle emphasizes simplicity in design. The idea is to write code that is as simple as possible while still achieving the required functionality. Over-complicated designs and solutions should be avoided.</p> <p>Example: <pre><code>def find_max(numbers):\n    return max(numbers)\n</code></pre></p> <p>A simple, straightforward function that uses built-in functionality, rather than reinventing the wheel.</p>"},{"location":"clear/#3-yagni-you-arent-gonna-need-it","title":"3. YAGNI - You Aren't Gonna Need It","text":"<p>This principle advises against writing code for functionality that is not required right now. The focus should be on the immediate requirements rather than building for potential future needs.</p> <p>Example: Avoiding this: <pre><code>def process_order(order):\n    # Adding features that aren't requested yet\n    if order.is_international:\n        calculate_shipping_cost(order)\n    # other unnecessary code\n</code></pre></p> <p>Instead, focus only on the current needs of your application.</p>"},{"location":"clear/#4-grasp-general-responsibility-assignment-software-patterns","title":"4. GRASP - General Responsibility Assignment Software Patterns","text":"<p>GRASP helps in determining how to assign responsibilities to different objects in a system. Some key GRASP principles include:</p> <ul> <li>Information Expert: Assign responsibility to the class that has the information needed to fulfill it.</li> <li>Creator: Assign class B the responsibility of creating objects of class A if one or more of these apply: B contains or aggregates A, B records A, or B closely uses A.</li> <li>Controller: Assign the responsibility of handling a system event to a class that represents the overall system, a use case, or a user interface.</li> </ul>"},{"location":"clear/#5-cqrs-command-query-responsibility-segregation","title":"5. CQRS - Command Query Responsibility Segregation","text":"<p>This pattern separates read and write operations in an application. It suggests that commands (write operations) and queries (read operations) should be handled differently, leading to cleaner and more efficient systems.</p> <p>Example: <pre><code># Query - to fetch data\ndef get_order(order_id):\n    return order_repository.get(order_id)\n\n# Command - to modify data\ndef place_order(order):\n    order_repository.save(order)\n</code></pre></p> <p>Commands modify state, while queries simply retrieve it, following CQRS.</p>"},{"location":"clear/#6-acid-atomicity-consistency-isolation-durability","title":"6. ACID - Atomicity, Consistency, Isolation, Durability","text":"<p>These are properties of database transactions designed to guarantee data integrity, especially in distributed systems.</p> <ul> <li>Atomicity: All operations in a transaction either complete or none do.</li> <li>Consistency: Transactions bring the system from one valid state to another.</li> <li>Isolation: Transactions are independent and invisible to others until completed.</li> <li>Durability: Once a transaction is committed, it is permanent.</li> </ul>"},{"location":"clear/#7-pols-principle-of-least-surprise","title":"7. POLS - Principle of Least Surprise","text":"<p>The design should follow patterns and structures that are intuitive and behave in a way users expect. Code should be simple and predictable, minimizing unexpected results.</p>"},{"location":"clear/#8-tdd-test-driven-development","title":"8. TDD - Test-Driven Development","text":"<p>This is a development process that emphasizes writing tests before writing the actual code. The idea is to first create a failing test, write the minimum amount of code to pass the test, and then refactor the code as necessary.</p>"},{"location":"clear/#9-law-of-demeter-lod-dont-talk-to-strangers","title":"9. Law of Demeter (LoD) - \"Don't Talk to Strangers\"","text":"<p>This principle encourages limiting the number of objects your code interacts with. An object should only talk to its immediate friends and should avoid chaining method calls that go beyond its direct collaborators.</p> <p>Example: <pre><code># Violates Law of Demeter\ncustomer.get_address().get_city().get_zip_code()\n\n# Better Approach\ncustomer.get_zip_code()\n</code></pre></p> <p>The second version reduces unnecessary coupling between objects.</p>"},{"location":"clear/#10-soc-separation-of-concerns","title":"10. SOC - Separation of Concerns","text":"<p>This principle states that a system should be organized so that each part of it addresses a distinct concern or aspect of the functionality, such as separating the UI logic from the business logic or database interaction.</p>"},{"location":"clear/#11-the-rule-of-three-refactoring","title":"11. The Rule of Three (Refactoring)","text":"<p>The rule of three is a code refactoring guideline: when you see the same code pattern in at least three places, it's time to refactor it into a reusable abstraction (like a function or class).</p>"},{"location":"clear/#12-damp-vs-wet","title":"12. DAMP vs. WET","text":"<ul> <li>DAMP: Descriptive and Meaningful Phrases \u2013 Code should have clear naming and be easy to understand by others.</li> <li>WET: Write Everything Twice \u2013 The opposite of DRY, meaning avoid unnecessary abstraction too early and focus on code clarity, refactoring only when absolutely needed.</li> </ul> <p>By following these design principles, you can ensure your code remains clean, easy to maintain, and adaptable to future requirements.</p>"},{"location":"pipeline/","title":"Pipeline","text":"<p>Developing a pipeline in Python can be an iterative process. Initially, you should focus on getting a basic version working, and then gradually add features and improve the code structure. Here's a step-by-step guide:</p>"},{"location":"pipeline/#step-1-set-up-the-basic-pipeline","title":"Step 1: Set Up the Basic Pipeline","text":"<ol> <li>Define the Pipeline's Objective:</li> <li> <p>Clearly define what the pipeline should accomplish. For example, it could be a data processing pipeline, a machine learning pipeline, or a CI/CD pipeline.</p> </li> <li> <p>Create a Simple, Linear Workflow:</p> </li> <li>Start with a simple script where all the tasks are executed sequentially.</li> <li>Example structure:      <pre><code>def step_1():\n    # Task 1 code\n    pass\n\ndef step_2():\n    # Task 2 code\n    pass\n\ndef main():\n    step_1()\n    step_2()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></li> <li> <p>Keep each function or task small and manageable.</p> </li> <li> <p>Test the Basic Pipeline:</p> </li> <li>Run the pipeline end-to-end to ensure all the steps work correctly.</li> <li>Focus on functionality, not optimization.</li> </ol>"},{"location":"pipeline/#step-2-add-logging-and-error-handling","title":"Step 2: Add Logging and Error Handling","text":"<ol> <li>Add Basic Logging:</li> <li>Introduce logging to track the progress of each step.</li> <li> <p>Example:      <pre><code>import logging\n\nlogging.basicConfig(level=logging.INFO)\n\ndef step_1():\n    logging.info(\"Starting Step 1\")\n    # Task 1 code\n    logging.info(\"Completed Step 1\")\n\ndef step_2():\n    logging.info(\"Starting Step 2\")\n    # Task 2 code\n    logging.info(\"Completed Step 2\")\n</code></pre></p> </li> <li> <p>Implement Error Handling:</p> </li> <li>Wrap critical sections of the code with <code>try-except</code> blocks to handle potential errors gracefully.</li> <li>Example:      <pre><code>def step_1():\n    try:\n        # Task 1 code\n        pass\n    except Exception as e:\n        logging.error(f\"Step 1 failed: {e}\")\n</code></pre></li> </ol>"},{"location":"pipeline/#step-3-modularize-the-code","title":"Step 3: Modularize the Code","text":"<ol> <li>Refactor Code into Modules:</li> <li>Move each step into separate Python files (modules) if the project grows in complexity.</li> <li> <p>Example structure:      <pre><code>pipeline/\n    __init__.py\n    step_1.py\n    step_2.py\n    main.py\n</code></pre></p> <ul> <li>Update the <code>main.py</code> script to import and run the steps.</li> </ul> </li> <li> <p>Use Configuration Files:</p> </li> <li>Introduce a configuration file (e.g., <code>config.yaml</code> or <code>config.json</code>) to store parameters instead of hard-coding them.</li> </ol>"},{"location":"pipeline/#step-4-add-features-and-flexibility","title":"Step 4: Add Features and Flexibility","text":"<ol> <li>Add Command-Line Arguments:</li> <li>Use libraries like <code>argparse</code> to allow running different parts of the pipeline or passing different parameters via the command line.</li> <li> <p>Example:      <pre><code>import argparse\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Pipeline\")\n    parser.add_argument(\"--step\", choices=[\"1\", \"2\"], help=\"Run specific step\")\n    args = parser.parse_args()\n\n    if args.step == \"1\":\n        step_1()\n    elif args.step == \"2\":\n        step_2()\n    else:\n        step_1()\n        step_2()\n\nif __name__ == \"__main__\":\n    main()\n</code></pre></p> </li> <li> <p>Introduce Parallelism:</p> </li> <li>If possible, use multithreading or multiprocessing to execute independent steps concurrently.</li> <li> <p>Example using <code>concurrent.futures</code>:      <pre><code>import concurrent.futures\n\nwith concurrent.futures.ThreadPoolExecutor() as executor:\n    executor.submit(step_1)\n    executor.submit(step_2)\n</code></pre></p> </li> <li> <p>Implement Data Validation:</p> </li> <li>Add checks to validate the input and output data for each step to ensure data consistency.</li> </ol>"},{"location":"pipeline/#step-5-optimize-and-refactor","title":"Step 5: Optimize and Refactor","text":"<ol> <li>Optimize Performance:</li> <li> <p>Profile the code to identify bottlenecks and optimize them (e.g., improve I/O operations, use efficient data structures).</p> </li> <li> <p>Refactor for Reusability:</p> </li> <li> <p>Look for repetitive code and refactor it into reusable functions or classes.</p> </li> <li> <p>Add Unit Tests:</p> </li> <li>Write tests for each step to ensure they work as expected.</li> <li>Use libraries like <code>unittest</code> or <code>pytest</code> for testing.</li> </ol>"},{"location":"pipeline/#step-6-documentation-and-maintenance","title":"Step 6: Documentation and Maintenance","text":"<ol> <li>Document the Pipeline:</li> <li> <p>Write clear documentation explaining how to use the pipeline, including dependencies, configuration, and instructions for running each step.</p> </li> <li> <p>Set Up Continuous Integration (CI):</p> </li> <li> <p>Automate the testing and deployment of the pipeline using a CI tool like GitHub Actions or Jenkins.</p> </li> <li> <p>Monitor and Maintain:</p> </li> <li>Set up monitoring and logging to track the pipeline in production and maintain it as requirements evolve.</li> </ol> <p>Starting with a simple version of the pipeline allows you to focus on the core functionality first, ensuring it works before adding complexity. By following these steps, you can iteratively improve your pipeline while maintaining code quality and performance.</p>"}]}